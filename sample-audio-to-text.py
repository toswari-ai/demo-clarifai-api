#!/usr/bin/env python3
"""
Clarifai Audio-to-Text (Speech Recognition) Demo

This script demonstrates how to use Clarifai's speech recognition models to convert
audio files into text transcriptions. This process is also known as speech-to-text
or automatic speech recognition (ASR).

The example uses AssemblyAI's audio transcription model available through Clarifai
to transcribe a sample audio file containing spoken words.

For more information about Clarifai's audio models, visit:
https://docs.clarifai.com/getting-started/quickstart

Author: Clarifai
Last Updated: 2025
Requirements: clarifai>=11.6.0
"""

# Import necessary libraries
from clarifai.client.model import Model  # Clarifai's Model class for API interactions
import os  # For accessing environment variables

# =============================================================================
# SECURITY SETUP: Get API credentials from environment variables
# =============================================================================
# Security best practice: Get PAT from environment variable instead of hardcoding it
# This prevents accidentally sharing your API key when sharing code
pat = os.getenv('CLARIFAI_PAT')

# Check if the PAT was successfully retrieved
if not pat:
    raise ValueError(
        "‚ùå Please set the CLARIFAI_PAT environment variable\n"
        "Linux/Mac: export CLARIFAI_PAT='your_actual_api_key_here'\n"
        "Windows: set CLARIFAI_PAT=your_actual_api_key_here\n"
        "Get your PAT from: https://clarifai.com/settings/security"
    )

# =============================================================================
# INPUT CONFIGURATION: Define the audio file to transcribe
# =============================================================================
# URL of the sample audio file we want to transcribe
# This audio file contains a "Good Morning" greeting that will be converted to text
audio_url = "https://s3.amazonaws.com/samples.clarifai.com/GoodMorning.wav"

print(f"ü§ñ Audio-to-Text Transcription")
print(f"üéß Processing audio: {audio_url}")
print("üìù Converting speech to text...")

# =============================================================================
# MODEL SETUP: Initialize the speech recognition model
# =============================================================================
# Using AssemblyAI's audio transcription model, which is specifically designed
# for high-quality speech recognition and transcription
# This model can handle various audio formats and accents
model_url = "https://clarifai.com/assemblyai/speech-recognition/models/audio-transcription"

print("üß† Initializing AssemblyAI speech recognition model...")

# Create model instance and make prediction with audio URL
# The predict_by_url() method sends the audio URL to the model for transcription
model_prediction = Model(url=model_url, pat=pat).predict_by_url(audio_url)

# =============================================================================
# RESULTS PROCESSING: Extract and display the transcription
# =============================================================================
print("\n" + "=" * 60)
print("üéØ Transcription Results:")
print("=" * 60)

try:
    # Extract the transcribed text from the model's response
    # The text is stored in the raw field of the text data
    transcribed_text = model_prediction.outputs[0].data.text.raw
    
    print(f"\nüìù Transcribed Text:")
    print(f'   "{transcribed_text}"')
    
    print(f"\n‚úÖ Audio transcription complete!")
    
    # Display additional information about the transcription
    if transcribed_text:
        word_count = len(transcribed_text.split())
        char_count = len(transcribed_text)
        print(f"\nüìä Transcription Statistics:")
        print(f"   ‚Ä¢ Word count: {word_count}")
        print(f"   ‚Ä¢ Character count: {char_count}")
    
except Exception as e:
    print(f"‚ùå Error processing transcription: {e}")
    print("üîß Troubleshooting tips:")
    print("   ‚Ä¢ Check if the audio URL is accessible")
    print("   ‚Ä¢ Verify the audio file format is supported (WAV, MP3, etc.)")
    print("   ‚Ä¢ Ensure your internet connection is stable")
    print("   ‚Ä¢ Try a different audio file or model")

# =============================================================================
# EDUCATIONAL INFORMATION AND NEXT STEPS
# =============================================================================
print(f"\nüí° Understanding speech recognition:")
print("   ‚Ä¢ Converts spoken language into written text")
print("   ‚Ä¢ Uses advanced AI models trained on vast amounts of audio data")
print("   ‚Ä¢ Can handle different accents, languages, and audio qualities")
print("   ‚Ä¢ Useful for transcription, voice commands, accessibility features")

print(f"\nüß† About the AssemblyAI model:")
print("   ‚Ä¢ Developed by AssemblyAI, a leader in speech recognition technology")
print("   ‚Ä¢ Optimized for high accuracy across various audio conditions")
print("   ‚Ä¢ Supports multiple audio formats (WAV, MP3, FLAC, etc.)")
print("   ‚Ä¢ Can handle background noise and multiple speakers")

print(f"\nüöÄ Try modifying this script:")
print("   ‚Ä¢ Change 'audio_url' to transcribe your own audio files")
print("   ‚Ä¢ Upload audio files to cloud storage and use their URLs")
print("   ‚Ä¢ Try different types of audio:")
print("     - Interviews or conversations")
print("     - Lectures or presentations")
print("     - Voice memos or recordings")
print("   ‚Ä¢ Experiment with different speech recognition models")
print("   ‚Ä¢ Add language detection or translation features")

print(f"\nüìö Learn more at: https://docs.clarifai.com/getting-started/quickstart")

# Raw output for debugging (optional)
print(f"\nüîß Raw API Response (for developers):")
print(f"   Model used: AssemblyAI audio-transcription")
print(f"   Input audio URL: {audio_url}")
if 'model_prediction' in locals():
    print(f"   Response type: {type(model_prediction.outputs[0].data.text)}")